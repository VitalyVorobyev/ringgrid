# Handoff: Validation Engineer â†’ Project Lead

- **Task:** PERF-003: Standardize Performance Validation Suite
- **Date:** 2026-02-16
- **Branch:** performance

## Work Completed

- Added canonical PERF validation runbook with exact required commands, artifacts, and pass/fail gates:
  - `.ai/workflows/perf-validation-suite-runbook.md`
  - session snapshot: `.ai/state/sessions/2026-02-16-PERF-003-validation-suite-runbook.md`
- Added blur-gate shell wrapper:
  - `tools/run_blur3_benchmark.sh`
- Standardized `.ai/templates/accuracy-report.md` around the three PERF validation gates.
- Standardized `.ai/templates/handoff-note.md` with required PERF validation artifact/delta fields.
- Updated workflow references to point future PERF tasks at the standardized suite:
  - `.ai/workflows/performance-optimization.md`
  - `.ai/workflows/handoff.md`
- Produced dry-run standardized report (PERF-004 -> PERF-005) proving the format is usable:
  - `.ai/state/sessions/2026-02-16-PERF-003-dry-run-accuracy-report.md`
- Marked PERF-003 complete in backlog and checked off spec acceptance criteria.

## Key Findings

- The same three benchmark scripts now have a stable runbook contract and output-path contract.
- The dry-run report captures all required deltas in one place, including threshold decisions.
- Existing PERF artifacts are sufficient for standardized reporting, but reference/distortion runs should copy `summary.json` to labeled snapshots to avoid overwrite ambiguity.

## Files Changed

| File | Change |
|------|--------|
| `.ai/workflows/perf-validation-suite-runbook.md` | New canonical PERF validation runbook (commands, artifacts, thresholds) |
| `.ai/state/sessions/2026-02-16-PERF-003-validation-suite-runbook.md` | Session snapshot of runbook at PERF-003 completion |
| `tools/run_blur3_benchmark.sh` | New shell wrapper for the standardized blur=3 gate |
| `.ai/templates/accuracy-report.md` | Reworked into three-gate PERF report template with baseline/after deltas |
| `.ai/templates/handoff-note.md` | Added required PERF validation gate artifact/delta sections |
| `.ai/workflows/performance-optimization.md` | Linked to PERF-003 runbook and standardized Phase-3 validation contract |
| `.ai/workflows/handoff.md` | Added PERF gate artifact + accuracy-report requirements |
| `.ai/state/sessions/2026-02-16-PERF-003-dry-run-accuracy-report.md` | New filled dry-run report (PERF-004 -> PERF-005) |
| `.ai/state/sessions/2026-02-16-PERF-003-spec.md` | Marked acceptance criteria complete |
| `.ai/state/backlog.md` | Moved PERF-003 from Active Sprint to Done with artifact links |
| `.ai/state/sessions/2026-02-16-PERF-003-validation-handoff.md` | This handoff note |

## Test Results

- **cargo test:** pass (`80 + 4 + 5` tests/doc-tests)
- **cargo clippy:** clean
- **cargo fmt:** clean

## Accuracy State

| Metric | Value |
|--------|-------|
| Center error (mean) | `0.3167405841 px -> 0.3148150564 px` (delta `-0.0019255277 px`) |
| Center error (p50) | `0.2943162899 px -> 0.2879433733 px` |
| Center error (p95) | `0.6770762139 px -> 0.6795488838 px` |
| Decode success rate | `1.000 -> 1.000` |
| Homography self-error (mean) | `0.2769789365 px -> 0.2755127028 px` |
| Homography vs-GT error (mean) | `0.1456968635 px -> 0.1443926836 px` |

## Performance State

| Benchmark | Result |
|-----------|--------|
| Runtime optimization benchmarks | not measured (PERF-003 is process/tooling standardization) |

## PERF Validation Gates (required for PERF tasks)

| Gate | Baseline Artifact | After Artifact | Center Mean Delta (px) | Recall Delta | H-Self Delta (px) | H-vs-GT Delta (px) | Status |
|------|-------------------|----------------|------------------------|--------------|-------------------|--------------------|--------|
| Blur-3 synth eval (`n=10`) | `tools/out/eval_perf004_blur3/det/aggregate.json` | `tools/out/eval_perf005_blur3/det/aggregate.json` | `-0.0019255277` | `+0.0019704433` | `-0.0014662338` | `-0.0013041799` | pass |
| Reference benchmark script | `.ai/state/sessions/2026-02-16-PERF-004-performance-handoff.md` | `.ai/state/sessions/2026-02-16-PERF-005-performance-handoff.md` | `~+0.0001` (`projective_center__none`) | `0.000` | n/a | n/a | pass |
| Distortion benchmark script | `.ai/state/sessions/2026-02-16-PERF-004-performance-handoff.md` | `.ai/state/sessions/2026-02-16-PERF-005-performance-handoff.md` | `-0.0031` (`external`), `-0.0023` (`self_undistort`), `-0.0117` (`none`) | `-0.0017` max (`none`) | n/a | n/a | pass |

## Accuracy Report Artifact (required for PERF tasks)

- Path to filled report from `.ai/templates/accuracy-report.md`: `.ai/state/sessions/2026-02-16-PERF-003-dry-run-accuracy-report.md`
- Threshold callout (`+0.01 px` center-mean gate): pass (`-0.0019255277 px`)

## Open Questions

- Should reference/distortion scripts gain a `--snapshot-label` flag to avoid manual `cp` for summary retention?

## Recommended Next Steps

1. Project Lead: accept PERF-003 and keep `.ai/workflows/perf-validation-suite-runbook.md` as the canonical validation contract for future PERF tasks.
2. Optional infra follow-up: add label/snapshot args to benchmark scripts so baseline/after summaries never overwrite the same path.

## Blocking Issues

None.
